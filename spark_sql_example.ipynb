{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, preprocessing and running OLAP analyses on large datasets with pySpark + SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example project demonstrating how to load some large datasets into Spark, \n",
    "then use the Spark.sql interface to perform OLAP analyses by running SQL queries.\n",
    "The data are from the Corporacion Favorita dataset, hosted on Kaggle\n",
    "(https://www.kaggle.com/c/favorita-grocery-sales-forecasting/data).\n",
    "They consist of purchases made at a chain of grocery stores (Favorita) which has locations throughout Ecuador.\n",
    "Each purchase has an item ID, store ID, date, and unit sales (which can be negative -> returns).\n",
    "These are in the main table unit_sales.\n",
    "There are two more tables with additional information:\n",
    "stores: store ID | geographic data\n",
    "items: item ID | product category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initialize Spark, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a spark session via spark builder\n",
    "#in this instance, we are running on the local machine \n",
    "#instead of local, could also have spark://IP address : port\n",
    "\n",
    "# e.g. spark://ec2-18-188-22-23.us-east-2.compute.amazonaws.com:7077\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName(\"test\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/cstoneki/Documents/data/favorita\"\n",
    "table_names = [\"unit_sales\", \"stores\", \"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_sales:            4.65 GB\n",
      "stores:                1.35 kB\n",
      "items:                99.45 kB\n"
     ]
    }
   ],
   "source": [
    "#just print the size of the files\n",
    "\n",
    "def format_file_size(size):\n",
    "    d = [(1,\"B\"), (1024,\"kB\"), (1024**2,\"MB\"), (1024**3,\"GB\"), (1024**4,\"TB\")]\n",
    "    d.reverse()\n",
    "    for (unit, name) in d:\n",
    "        if(size >= 0.1*unit or unit==1):\n",
    "            return (\"%.2f \"+name)%(size/unit)\n",
    "    \n",
    "\n",
    "\n",
    "for t in table_names:\n",
    "    s1 = t + \":\"\n",
    "    s2 = format_file_size((int(os.path.getsize(folder_path + \"/\" + t + \".csv\"))))\n",
    "    print(s1 + (30 - len(s1) - len(s2))*' ' + s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So unit_sales is a fairly large file, but still small enough that it can be used to demonstrate use of Spark on a personal computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use knowledge of tables to specify correct data types\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType\n",
    "\n",
    "schemas = {}\n",
    "\n",
    "# Specify column names and types\n",
    "schemas['unit_sales'] = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"date\", StringType()),\n",
    "    StructField(\"store_nbr\", IntegerType()),\n",
    "    StructField(\"item_nbr\", IntegerType()),\n",
    "    StructField(\"unit_sales\", FloatType()),\n",
    "    StructField(\"onpromotion\", IntegerType())\n",
    "])\n",
    "schemas['stores'] = StructType([\n",
    "    StructField(\"store_nbr\", IntegerType()),\n",
    "    StructField(\"city\", StringType()),\n",
    "    StructField(\"state\", StringType()),\n",
    "    StructField(\"type\", StringType()),\n",
    "    StructField(\"cluster\", IntegerType())\n",
    "])\n",
    "schemas['items'] = StructType([\n",
    "    StructField(\"item_nbr\", IntegerType()),\n",
    "    StructField(\"family\", StringType()),\n",
    "    StructField(\"class\", IntegerType()),\n",
    "    StructField(\"perishable\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded unit_sales in 1.16 s\n",
      "Loaded stores in 0.03 s\n",
      "Loaded items in 0.02 s\n"
     ]
    }
   ],
   "source": [
    "for t in table_names:\n",
    "    t0 = time.time()\n",
    "    df = spark.read.csv(folder_path + \"/\" + t + \".csv\", header=True, schema=schemas[t])\n",
    "    df.createOrReplaceTempView(t)\n",
    "    t_elapsed = time.time() - t0\n",
    "    print(\"Loaded \"+t+\" in %.2f s\"%t_elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_sales\n",
      "+---+----------+---------+--------+----------+-----------+\n",
      "| id|      date|store_nbr|item_nbr|unit_sales|onpromotion|\n",
      "+---+----------+---------+--------+----------+-----------+\n",
      "|  0|2013-01-01|       25|  103665|       7.0|       null|\n",
      "|  1|2013-01-01|       25|  105574|       1.0|       null|\n",
      "|  2|2013-01-01|       25|  105575|       2.0|       null|\n",
      "+---+----------+---------+--------+----------+-----------+\n",
      "\n",
      "stores\n",
      "+---------+-----+---------+----+-------+\n",
      "|store_nbr| city|    state|type|cluster|\n",
      "+---------+-----+---------+----+-------+\n",
      "|        1|Quito|Pichincha|   D|     13|\n",
      "|        2|Quito|Pichincha|   D|     13|\n",
      "|        3|Quito|Pichincha|   D|      8|\n",
      "+---------+-----+---------+----+-------+\n",
      "\n",
      "items\n",
      "+--------+---------+-----+----------+\n",
      "|item_nbr|   family|class|perishable|\n",
      "+--------+---------+-----+----------+\n",
      "|   96995|GROCERY I| 1093|         0|\n",
      "|   99197|GROCERY I| 1067|         0|\n",
      "|  103501| CLEANING| 3008|         0|\n",
      "+--------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show some information on the tables - \n",
    "for t in table_names:\n",
    "    print(t)\n",
    "    query = \"SELECT * FROM \" + t + \" LIMIT 3\"\n",
    "    spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. OLAP analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Favorita runs large grocery stores that sell many different types of products.\n",
    "As a first step, we want to find out how much of the total sales volume each individual product family accounts for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the percentage of total sales represented by each product family\n",
    "query = \"\"\"\n",
    "SELECT family, 100*sales_by_family/(SUM(sales_by_family) OVER()) AS percent_sales\n",
    "FROM\n",
    "(SELECT i.family AS family, SUM(u.unit_sales) AS sales_by_family\n",
    " FROM unit_sales AS u\n",
    " INNER JOIN items AS i\n",
    " ON i.item_nbr = u.item_nbr\n",
    " GROUP BY i.family)\n",
    "\"\"\"\n",
    "\n",
    "df2 = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|              family|percent_sales|\n",
      "+--------------------+-------------+\n",
      "|          AUTOMOTIVE|         0.05|\n",
      "|           BABY CARE|         0.00|\n",
      "|              BEAUTY|         0.03|\n",
      "|           BEVERAGES|        20.21|\n",
      "|               BOOKS|         0.00|\n",
      "|        BREAD/BAKERY|         3.92|\n",
      "|         CELEBRATION|         0.07|\n",
      "|            CLEANING|         9.08|\n",
      "|               DAIRY|         6.01|\n",
      "|                DELI|         2.25|\n",
      "|                EGGS|         1.45|\n",
      "|        FROZEN FOODS|         1.31|\n",
      "|           GROCERY I|        31.99|\n",
      "|          GROCERY II|         0.18|\n",
      "|            HARDWARE|         0.01|\n",
      "|  HOME AND KITCHEN I|         0.17|\n",
      "| HOME AND KITCHEN II|         0.14|\n",
      "|     HOME APPLIANCES|         0.00|\n",
      "|           HOME CARE|         1.49|\n",
      "|          LADIESWEAR|         0.06|\n",
      "|     LAWN AND GARDEN|         0.05|\n",
      "|            LINGERIE|         0.06|\n",
      "|    LIQUOR,WINE,BEER|         0.72|\n",
      "|           MAGAZINES|         0.02|\n",
      "|               MEATS|         2.90|\n",
      "|       PERSONAL CARE|         2.29|\n",
      "|        PET SUPPLIES|         0.03|\n",
      "|PLAYERS AND ELECT...|         0.05|\n",
      "|             POULTRY|         2.97|\n",
      "|      PREPARED FOODS|         0.82|\n",
      "|             PRODUCE|        11.43|\n",
      "|SCHOOL AND OFFICE...|         0.03|\n",
      "|             SEAFOOD|         0.19|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number \n",
    "df2 = df2.orderBy(\"family\", ascending=True)\n",
    "df2.select(['family', format_number(df2['percent_sales'], 2).alias('percent_sales')]).show(df2.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main categories are beverages, grocery I and produce. Next, we want to break down the purchases by geographic location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         city|\n",
      "+-------------+\n",
      "|      Quevedo|\n",
      "|       Cuenca|\n",
      "|     Guaranda|\n",
      "|Santo Domingo|\n",
      "|       Playas|\n",
      "|         Puyo|\n",
      "|        Quito|\n",
      "|        Manta|\n",
      "|    Latacunga|\n",
      "|    Guayaquil|\n",
      "|         Loja|\n",
      "|       Ibarra|\n",
      "|    El Carmen|\n",
      "|       Ambato|\n",
      "|      Machala|\n",
      "|        Daule|\n",
      "|      Cayambe|\n",
      "|      Salinas|\n",
      "|     Libertad|\n",
      "|     Babahoyo|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|               state|\n",
      "+--------------------+\n",
      "|              Manabi|\n",
      "|            Cotopaxi|\n",
      "|           Pichincha|\n",
      "|          Chimborazo|\n",
      "|              Guayas|\n",
      "|                Loja|\n",
      "|         Santa Elena|\n",
      "|            Imbabura|\n",
      "|              El Oro|\n",
      "|               Azuay|\n",
      "|             Bolivar|\n",
      "|          Tungurahua|\n",
      "|             Pastaza|\n",
      "|Santo Domingo de ...|\n",
      "|            Los Rios|\n",
      "|          Esmeraldas|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#what geographic information do we have?\n",
    "spark.sql(\"SELECT DISTINCT city FROM stores\").show()\n",
    "spark.sql(\"SELECT DISTINCT state FROM stores\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The states can be divided into three regions, introduce these to get a more meaningful, larger-scale grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a new table in the spark session, linking states to regions\n",
    "#this will normally be saved and available in subsequent sessions\n",
    "#to make things simple, clear it in each run since it's very small\n",
    "_ = spark.sql(\"DROP TABLE regions\")\n",
    "_ = spark.sql(\"CREATE TABLE IF NOT EXISTS regions(region varchar(255), state varchar(255))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if regions already contains any data, insert if it does not\n",
    "if(spark.sql(\"SELECT * FROM regions LIMIT 1\").count() < 1):\n",
    "\n",
    "    la_sierra_states = [\"Carchi\", \"Imbabura\", \"Pichincha\",\\\n",
    "                    \"Cotopaxi\", \"Tungurahua\", \"Bolivar\",\\\n",
    "                    \"Chimborazo\", \"Canar\", \"Azuay\", \"Loja\"]\n",
    "\n",
    "    la_costa_states  = [\"Esmeraldas\", \"Manabi\", \"Santo Domingo de ...\",\\\n",
    "                        \"Los Rios\", \"Santa Elena\", \"Guayas\", \"El Oro\"]\n",
    "    \n",
    "    el_oriente_states = [\"Sucumbios\", \"Napo\", \"Orellana\", \"Pastaza\", \"Morona Santiago\", \"Zamora Chinchipe\"]\n",
    "    \n",
    "    #insert records\n",
    "    #note that spark requires INSERT INTO ... SELECT\n",
    "    #INSERT INTO ... VALUES is not implemented\n",
    "    for state in la_sierra_states:\n",
    "        spark.sql(\"INSERT INTO regions SELECT temp.* FROM (SELECT 'La Sierra', \" + \"'\" + state +\"'\" + \") temp\")\n",
    "    for state in la_costa_states:\n",
    "        spark.sql(\"INSERT INTO regions SELECT temp.* FROM (SELECT 'La Costa', \" + \"'\" + state +\"'\" + \") temp\")\n",
    "    for state in el_oriente_states:\n",
    "        spark.sql(\"INSERT INTO regions SELECT temp.* FROM (SELECT 'El Oriente', \" + \"'\" + state +\"'\" + \") temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|    region|               state|\n",
      "+----------+--------------------+\n",
      "|  La Costa|              El Oro|\n",
      "|  La Costa|            Los Rios|\n",
      "| La Sierra|               Azuay|\n",
      "| La Sierra|          Chimborazo|\n",
      "|El Oriente|    Zamora Chinchipe|\n",
      "|El Oriente|             Pastaza|\n",
      "| La Sierra|            Imbabura|\n",
      "|  La Costa|          Esmeraldas|\n",
      "|El Oriente|     Morona Santiago|\n",
      "|  La Costa|         Santa Elena|\n",
      "|  La Costa|              Guayas|\n",
      "| La Sierra|          Tungurahua|\n",
      "|  La Costa|              Manabi|\n",
      "|El Oriente|            Orellana|\n",
      "| La Sierra|                Loja|\n",
      "| La Sierra|               Canar|\n",
      "| La Sierra|              Carchi|\n",
      "| La Sierra|             Bolivar|\n",
      "|  La Costa|Santo Domingo de ...|\n",
      "| La Sierra|            Cotopaxi|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM regions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use GROUP BY ROLLUP to get a pivot table, joining data from all tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a summary of sales by product family, further broken down into region\n",
    "query = \"\"\"\n",
    "SELECT i.family, r.region, SUM(unit_sales) AS total_sales\n",
    "FROM unit_sales AS u \n",
    "LEFT JOIN items AS i\n",
    "ON i.item_nbr = u.item_nbr\n",
    "LEFT JOIN stores AS s\n",
    "ON s.store_nbr = u.store_nbr\n",
    "LEFT JOIN regions AS r\n",
    "ON r.state = s.state\n",
    "WHERE r.region IS NOT NULL AND i.family IS NOT NULL\n",
    "GROUP BY ROLLUP(i.family, r.region)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------------+\n",
      "|              family|    region|     total_sales|\n",
      "+--------------------+----------+----------------+\n",
      "|                null|      null|1,037,775,952.75|\n",
      "|          AUTOMOTIVE|      null|      528,085.00|\n",
      "|          AUTOMOTIVE|El Oriente|        3,677.00|\n",
      "|          AUTOMOTIVE|  La Costa|      149,390.00|\n",
      "|          AUTOMOTIVE| La Sierra|      375,018.00|\n",
      "|           BABY CARE|      null|        9,189.00|\n",
      "|           BABY CARE|El Oriente|          196.00|\n",
      "|           BABY CARE|  La Costa|        3,456.00|\n",
      "|           BABY CARE| La Sierra|        5,537.00|\n",
      "|              BEAUTY|      null|      324,079.00|\n",
      "|              BEAUTY|El Oriente|        1,050.00|\n",
      "|              BEAUTY|  La Costa|       67,781.00|\n",
      "|              BEAUTY| La Sierra|      255,248.00|\n",
      "|           BEVERAGES|      null|  210,618,755.00|\n",
      "|           BEVERAGES|El Oriente|      857,889.00|\n",
      "|           BEVERAGES|  La Costa|   59,062,960.00|\n",
      "|           BEVERAGES| La Sierra|  150,697,906.00|\n",
      "|               BOOKS|      null|        6,205.00|\n",
      "|               BOOKS|  La Costa|          853.00|\n",
      "|               BOOKS| La Sierra|        5,352.00|\n",
      "|        BREAD/BAKERY|      null|   40,783,261.02|\n",
      "|        BREAD/BAKERY|El Oriente|       90,575.00|\n",
      "|        BREAD/BAKERY|  La Costa|   12,503,082.70|\n",
      "|        BREAD/BAKERY| La Sierra|   28,189,603.32|\n",
      "|         CELEBRATION|      null|      723,192.00|\n",
      "|         CELEBRATION|El Oriente|        6,076.00|\n",
      "|         CELEBRATION|  La Costa|      180,239.00|\n",
      "|         CELEBRATION| La Sierra|      536,877.00|\n",
      "|            CLEANING|      null|   93,201,436.00|\n",
      "|            CLEANING|El Oriente|      416,453.00|\n",
      "|            CLEANING|  La Costa|   27,404,886.00|\n",
      "|            CLEANING| La Sierra|   65,380,097.00|\n",
      "|               DAIRY|      null|   62,782,061.00|\n",
      "|               DAIRY|El Oriente|      203,463.00|\n",
      "|               DAIRY|  La Costa|   16,114,952.00|\n",
      "|               DAIRY| La Sierra|   46,463,646.00|\n",
      "|                DELI|      null|   23,091,554.64|\n",
      "|                DELI|El Oriente|      109,294.00|\n",
      "|                DELI|  La Costa|    6,181,680.65|\n",
      "|                DELI| La Sierra|   16,800,579.99|\n",
      "|                EGGS|      null|   14,933,632.00|\n",
      "|                EGGS|El Oriente|       35,378.00|\n",
      "|                EGGS|  La Costa|    4,771,877.00|\n",
      "|                EGGS| La Sierra|   10,126,377.00|\n",
      "|        FROZEN FOODS|      null|   13,657,909.03|\n",
      "|        FROZEN FOODS|El Oriente|       49,687.75|\n",
      "|        FROZEN FOODS|  La Costa|    3,553,930.39|\n",
      "|        FROZEN FOODS| La Sierra|   10,054,290.90|\n",
      "|           GROCERY I|      null|  330,728,958.05|\n",
      "|           GROCERY I|El Oriente|    1,570,262.31|\n",
      "|           GROCERY I|  La Costa|   92,468,711.64|\n",
      "|           GROCERY I| La Sierra|  236,689,984.10|\n",
      "|          GROCERY II|      null|    1,909,293.00|\n",
      "|          GROCERY II|El Oriente|        3,922.00|\n",
      "|          GROCERY II|  La Costa|      332,936.00|\n",
      "|          GROCERY II| La Sierra|    1,572,435.00|\n",
      "|            HARDWARE|      null|      100,013.00|\n",
      "|            HARDWARE|El Oriente|          698.00|\n",
      "|            HARDWARE|  La Costa|       31,090.00|\n",
      "|            HARDWARE| La Sierra|       68,225.00|\n",
      "|  HOME AND KITCHEN I|      null|    1,783,589.00|\n",
      "|  HOME AND KITCHEN I|El Oriente|       26,904.00|\n",
      "|  HOME AND KITCHEN I|  La Costa|      516,358.00|\n",
      "|  HOME AND KITCHEN I| La Sierra|    1,240,327.00|\n",
      "| HOME AND KITCHEN II|      null|    1,447,672.00|\n",
      "| HOME AND KITCHEN II|El Oriente|       12,790.00|\n",
      "| HOME AND KITCHEN II|  La Costa|      404,706.00|\n",
      "| HOME AND KITCHEN II| La Sierra|    1,030,176.00|\n",
      "|     HOME APPLIANCES|      null|       40,185.00|\n",
      "|     HOME APPLIANCES|El Oriente|          228.00|\n",
      "|     HOME APPLIANCES|  La Costa|        9,832.00|\n",
      "|     HOME APPLIANCES| La Sierra|       30,125.00|\n",
      "|           HOME CARE|      null|   15,314,939.00|\n",
      "|           HOME CARE|El Oriente|      105,959.00|\n",
      "|           HOME CARE|  La Costa|    4,222,275.00|\n",
      "|           HOME CARE| La Sierra|   10,986,705.00|\n",
      "|          LADIESWEAR|      null|      632,315.00|\n",
      "|          LADIESWEAR|El Oriente|          350.00|\n",
      "|          LADIESWEAR|  La Costa|       56,204.00|\n",
      "|          LADIESWEAR| La Sierra|      575,761.00|\n",
      "|     LAWN AND GARDEN|      null|      541,951.00|\n",
      "|     LAWN AND GARDEN|El Oriente|           12.00|\n",
      "|     LAWN AND GARDEN|  La Costa|      150,536.00|\n",
      "|     LAWN AND GARDEN| La Sierra|      391,403.00|\n",
      "|            LINGERIE|      null|      606,608.00|\n",
      "|            LINGERIE|El Oriente|        4,781.00|\n",
      "|            LINGERIE|  La Costa|      200,863.00|\n",
      "|            LINGERIE| La Sierra|      400,964.00|\n",
      "|    LIQUOR,WINE,BEER|      null|    7,522,185.00|\n",
      "|    LIQUOR,WINE,BEER|El Oriente|       23,066.00|\n",
      "|    LIQUOR,WINE,BEER|  La Costa|    2,666,041.00|\n",
      "|    LIQUOR,WINE,BEER| La Sierra|    4,833,078.00|\n",
      "|           MAGAZINES|      null|      257,195.00|\n",
      "|           MAGAZINES|El Oriente|        1,915.00|\n",
      "|           MAGAZINES|  La Costa|       57,908.00|\n",
      "|           MAGAZINES| La Sierra|      197,372.00|\n",
      "|               MEATS|      null|   30,396,530.46|\n",
      "|               MEATS|El Oriente|       70,522.04|\n",
      "|               MEATS|  La Costa|    6,619,732.49|\n",
      "|               MEATS| La Sierra|   23,706,275.94|\n",
      "|       PERSONAL CARE|      null|   23,554,789.00|\n",
      "|       PERSONAL CARE|El Oriente|      107,083.00|\n",
      "|       PERSONAL CARE|  La Costa|    6,681,448.00|\n",
      "|       PERSONAL CARE| La Sierra|   16,766,258.00|\n",
      "|        PET SUPPLIES|      null|      351,497.00|\n",
      "|        PET SUPPLIES|El Oriente|          652.00|\n",
      "|        PET SUPPLIES|  La Costa|       81,780.00|\n",
      "|        PET SUPPLIES| La Sierra|      269,065.00|\n",
      "|PLAYERS AND ELECT...|      null|      545,247.00|\n",
      "|PLAYERS AND ELECT...|El Oriente|        3,776.00|\n",
      "|PLAYERS AND ELECT...|  La Costa|      113,569.00|\n",
      "|PLAYERS AND ELECT...| La Sierra|      427,902.00|\n",
      "|             POULTRY|      null|   31,167,154.32|\n",
      "|             POULTRY|El Oriente|       83,227.73|\n",
      "|             POULTRY|  La Costa|    6,544,831.52|\n",
      "|             POULTRY| La Sierra|   24,539,095.07|\n",
      "|      PREPARED FOODS|      null|    8,503,504.85|\n",
      "|      PREPARED FOODS|El Oriente|       30,439.00|\n",
      "|      PREPARED FOODS|  La Costa|    1,840,262.17|\n",
      "|      PREPARED FOODS| La Sierra|    6,632,803.68|\n",
      "|             PRODUCE|      null|  119,466,332.23|\n",
      "|             PRODUCE|El Oriente|      268,022.92|\n",
      "|             PRODUCE|  La Costa|   29,879,623.50|\n",
      "|             PRODUCE| La Sierra|   89,318,685.81|\n",
      "|SCHOOL AND OFFICE...|      null|      262,645.00|\n",
      "|SCHOOL AND OFFICE...|El Oriente|          418.00|\n",
      "|SCHOOL AND OFFICE...|  La Costa|       61,218.00|\n",
      "|SCHOOL AND OFFICE...| La Sierra|      201,009.00|\n",
      "|             SEAFOOD|      null|    1,983,991.16|\n",
      "|             SEAFOOD|El Oriente|        1,435.00|\n",
      "|             SEAFOOD|  La Costa|      300,438.08|\n",
      "|             SEAFOOD| La Sierra|    1,682,118.08|\n",
      "+--------------------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.orderBy([\"family\", \"region\"], ascending=True)\n",
    "df.select(['family', 'region', format_number(df['total_sales'], 2).alias('total_sales')]).show(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final pivot table shows total sales by product family, further subdivided by region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to look at seasonal (month-by-month) trends in purchases, focusing on a few classes of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT MONTH(CAST(u.date AS DATE)) AS month, SUM(u.unit_sales) AS total_sales\n",
    "FROM unit_sales as u\n",
    "LEFT JOIN items AS i\n",
    "ON i.item_nbr = u.item_nbr\n",
    "WHERE i.family IN ('LAWN AND GARDEN')\n",
    "GROUP BY month\n",
    "ORDER BY month\n",
    "\"\"\"\n",
    "df3 = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|month|total_sales|\n",
      "+-----+-----------+\n",
      "|    1|  48,207.00|\n",
      "|    2|  53,696.00|\n",
      "|    3|  52,824.00|\n",
      "|    4|  49,691.00|\n",
      "|    5|  63,874.00|\n",
      "|    6|  53,628.00|\n",
      "|    7|  54,999.00|\n",
      "|    8|  40,458.00|\n",
      "|    9|  27,286.00|\n",
      "|   10|  29,538.00|\n",
      "|   11|  28,116.00|\n",
      "|   12|  46,521.00|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df3.orderBy([\"month\"], ascending=True)\n",
    "df3.select(['month', format_number(df3['total_sales'], 2).alias('total_sales')]).show(df3.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sales of Lawn and Garden products show some fairly strong seasonality. Total sales in the fall months (Sep-Nov) are around 60% of those in the winter-spring-early summer months (Jan-Jul)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the example analyses using pySpark + SQL. A worthwhile next step would be to integrate Spark with Tableau to create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
